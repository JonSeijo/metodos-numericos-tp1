% Cita textual seccion Desarrolo:

% Deben explicarse los metodos numericos que utilizaron
% y su aplicacion al problema concreto involucrado en el trabajo practico.
% Se deben mencionar los pasos que siguieron para implementar
% los algoritmos, las dificultades que fueron encontrando y la
% descripcion de como las fueron resolviendo.

% Explicar tambien como fueron planteadas y realizadas las
% mediciones experimentales. Los ensayos fallidos, hipotesis y
% conjeturas equivocadas, experimentos y metodos malogrados deben
% figurar en esta seccion,
% con una breve explicacion de los motivos de estas fallas
% (en caso de ser conocidas).

\section{Cálculo de normales}

\todo[inline]{Explicar un poco mas que representa el sistema y como resolviendolo logramos lo de las normales. Ver que quiza esto convenga ponerlo luego de describir los metodos}

\subsection{Eliminación Gaussiana}

Tenemos un sistema listo para resolver, dónde sólo los $m_i$ son incógnitas:

% Sistema de matrices original
\[
\begin{pmatrix}
    s_{x}^{1} & s_{y}^{1} & s_{z}^{1} \\
    s_{x}^{2} & s_{y}^{2} & s_{z}^{2} \\
    s_{x}^{3} & s_{y}^{3} & s_{z}^{3}
\end{pmatrix}
\begin{pmatrix}
    m_{x} \\
    m_{y} \\
    m_{z}
\end{pmatrix}
=
\begin{pmatrix}
    I_{1} \\
    I_{2} \\
    I_{3}
\end{pmatrix}
\]

La pregunta ahora es ¿cómo lo resolvemos?. Dado que en principio no sabemos cómo, nos gustaría llevarlo a una forma equivalente que sea mas fácil de resolver. Podemos hacer esta conversión a un sistema equivalente usando el algortimo de eliminación de Gauss. Lo que hace este algortimo es llevar una matriz a su forma triangular superior, de dónde luego es muy sencillo hacer los despejes finales. \\

El pseudocódigo del algoritmo de Gauss es el siguiente:

\begin{algorithm}[H]
\begin{algorithmic}
\Function{EliminacionGaussiana}{Matriz M[$n$][$m$]}

    \For{$k \in [1..min(n,m)]$ }
        \For{$i \in [k+1..m]$ }

            \If{M[$k$][$k$] $\neq 0$}
                \State $mult \gets $M[$i$][$k$] $/$ M[$k$][$k$]
                \For{$j \in [k+1..n]$}

                    \State M[$i$][$j$] $\gets$ M[$i$][$j$] - mult*M[$k$][$j$]

                \EndFor
            \Else
                \State Hay un cero en la diagonal!
            \EndIf
        \EndFor
    \EndFor

\EndFunction
\end{algorithmic}
\end{algorithm}

Como puede verse, funciona correctamente solo \textbf{suponiendo que no hay ceros en la diagonal}. Es claro que puede modificarse para que realice intercambios de filas y no tenga el problema del cero, veamos que para nuestro problema no es importante. En nuestra implementación aplicaremos el algoritmo de Gauss en la siguiente matriz ampliada:

% Matriz ampliada
\[
\begin{pmatrix}[ccc|c]
    s_{x}^{1} & s_{y}^{1} & s_{z}^{1} & I_{1} \\
    s_{x}^{2} & s_{y}^{2} & s_{z}^{2} & I_{2} \\
    s_{x}^{3} & s_{y}^{3} & s_{z}^{3} & I_{3}
\end{pmatrix}
\]

Nuestros $s_{j}^{i}$ incialmente son todos distintos de cero. Además, tomamos todas las combinaciones posibles de tres luces y vimos que siempre son linealmente independientes, por lo tanto nunca vamos a hallar un cero en la diagonal y no es necesario aplicar permutaciones. Esto cobrará importancia cuando querramos aplicar factorización LU. \\

Dado que pudimos triangular correctamente la matriz ampliada, entonces ya estamos en condiciones de despejar de nuestra matriz de 3 x 4:

\[
\begin{pmatrix}[ccc|c]
    m_{1,1}   & m_{1,2} & m_{1,3} & m_{1, 4} \\
    0         & m_{2,2} & m_{2,3} & m_{2, 4} \\
    0         & 0       & m_{3,3} & m_{3, 4}
\end{pmatrix}
\]

\begin{algorithm}[H]
\begin{algorithmic}
\Function{Despejar}{Matriz M[$n$][$m$]}

    // En X se guardan los m-1 coeficientes solución (Recordemos que M es ampliada)
    \State X[$m-1$] $\gets \{\}$ \\

    \For{$j \in [1..m-1]$ }  (j es indice de columna)

        \If{M[$j$][$j$] $\neq 0$}

            \State X[$j$] $\gets$ M[$j$][$m$] / M[$j$][$j$]

            \For{$i \in [j-1 .. 0]$ }  (i es indice de fila)

                \State M[$i$][$m$] $\gets$ M[$i$][$m$] - ( M[$i$][$j$] * X[$j$] )

            \EndFor

        \Else
            \State Hay un cero en la diagonal!
        \EndIf
    \EndFor

    \State Retornar X

\EndFunction
\end{algorithmic}
\end{algorithm}


\subsection{Factorización LU}

Recordemos nuestro sistema para hallar las normales:
\[
\begin{pmatrix}
    s_{x}^{1} & s_{y}^{1} & s_{z}^{1} \\
    s_{x}^{2} & s_{y}^{2} & s_{z}^{2} \\
    s_{x}^{3} & s_{y}^{3} & s_{z}^{3}
\end{pmatrix}
\begin{pmatrix}
    m_{x} \\
    m_{y} \\
    m_{z}
\end{pmatrix}
=
\begin{pmatrix}
    I_{1} \\
    I_{2} \\
    I_{3}
\end{pmatrix}
\]

Una vez fijas las luces a utilizar (en este caso 1,2 y 3) para despejar la normal en cada píxel, debemos resolver el sistema en cada píxel. Es decir, estaremos traingulando una y otra vez una matriz dónde lo único que cambia es el término a la derecha de la igualdad. Por lo tanto, es interesante plantearse si existe una forma de evitar aplicar Gauss en cada punto. \\

La factorización LU podría no existir, pero veámos de que se trata. Dada una matriz $A$, la factorización LU consiste en encontrar dos matrices: una matriz $L$ triangular inferior con unos en la diagonal y una matriz $U$ triangular superior, de forma que se cumpla

\begin{center}
$A$ = $L$.$U$
\end{center}

% Quiza explicar mejor esto
Por lo visto en clase, puede demostrarse que la $L$ tiene en la diagonal unos, ceros por arriba, y por debajo los multiplicadores que se utilizaron en la eliminación Gaussiana para colocar un cero en la triangulación. En la $U$ se colocan ceros debajo de la diagonal y en el resto los coeficientes que quedaron en la matriz ya triangulada. \\

Digamos entonces que ya conocemos la factorización LU para una matriz dada, ¿Cómo la utilizamos para resolver nuestro sistema?

\begin{center}
    $Ax = b$ $\iff$ $LUx = b$
\end{center}

Si consideramos $Ux = y$, nos queda para resolver:

\begin{center}
    $Ly = b$
\end{center}

Donde $L$ es triangular inferior. Por lo tanto podemos despejar y obtener $y$ sin necesidad de aplicar eliminación Gaussiana. Una vez que conocemos $y$, como $U$ también esta triangulada despejamos en:

\begin{center}
    $Ux = y$
\end{center}

Obteniendo así el $x$ que queríamos encontrar inicialmente. \\

Por lo explicado en la sección anterior (independencia lineal de las luces) sabemos que podemos aplicar Gauss normalmente sin encontrarnos con ceros en la diagonal. Es decir, podemos terminar el proceso de triangulación sin tener que haccer ninguna permutación de filas. \\

Por lo visto en la clase teórica, si podemos triangular una matriz usando Gauss sin tener que permutar filas, es suficiente para afirmar que la factorización LU existe, entonces con el procedimiento explicado podemos hallar la descomposicion de nuestra matriz de luces y resolver el sistema mas eficientemente. \\

\section{Estimacion de profundidades}

Utilizando los métodos anteriores pudimos resolver el sistema que incluye las luces y calcular las normales para todo píxel de la imagen. Recordemos que para un cierto píxel $(a, b)$ la normal en ese punto es de la forma:

\begin{center}
$n^{(a,b)} = (n_{x}^{a,b}, n_{y}^{a,b}, n_{z}^{a,b})$
\end{center}

A partir de aquí en ocasiones omitiremos el supraíndice $(a,b)$ para relajar la notación cuando es claro cuál es el píxel del que hablamos. Siguiendo con la técnica de fotometría estéreo, el siguiente paso a realizar es el cálculo de las profundidades utilizando estas normales. Para esto, consideramos una aproximación al plano tangente de cada píxel. La ecuaciones que tenemos que resolver son las siguientes, para cada píxel $(x ,y)$.

\begin{center}
\[
    \begin{dcases}
        n_{y} +  n_{z} * (z_{x, y+1} - z_{x, y}) = 0 \\
        n_{x} +  n_{z} * (z_{x+1, y} - z_{x, y}) = 0
    \end{dcases}
\]
\end{center}
O equivalentemente
\begin{center}
\[\begin{dcases}
        n_{z} * z_{x, y+1} - n_{z} *  z_{x, y} = n_{y}  \\
        n_{z} * z_{x+1, y} - n_{z} *  z_{x, y} = n_{x}
    \end{dcases}
\]
\end{center}

Consideremos como sería el sistema matricial para una imagen de 2x3 pixeles, y veremos como puede generalizarse: \\

% \dots \ddots \vdots

\[
\underbrace{
\begin{pmatrix}
    % - n_{z}^{1,1}  &  0                      & 0  & n_{z}^{1,1}    & 0 & 0 & 0 & 0 & 0 \\
    % - n_{z}^{1,1}  &  n_{z}^{1,1}  &  0  & 0 & 0  &  0               & 0 & 0 & 0 & \\
    % 0 & - n_{z}^{1,2}  &  0                   & 0 &  n_{z}^{1,2}   & 0 & 0 & 0 & 0     \\
    % 0 & - n_{z}^{1,2}  &  n_{z}^{1,2}   & 0 &  0  &  0  &  0         & 0 & 0     \\
    % 0 & 0 & - n_{z}^{1,3}  &  0             & 0   &  n_{z}^{1,3}   & 0 & 0 & 0  \\
    % % 0 & 0 & - n_{z}^{1,3}  &  n_{z}^{1,3} & 0 &  0  &  0  &  0  & 0       \\
    % 0 & 0 &  0  &  0 & 0 &  0  &  0  &  0  & 0       \\
    % 0 & 0 & 0 & - n_{z}^{2,1}  &  0         & 0     &  n_{z}^{2,1} & 0 & 0      \\
    % 0 & 0 & 0 & - n_{z}^{2,1}  &  n_{z}^{2,1} & 0 &  0  &  0  &  0      \\
    % 0 & 0 & 0 & 0 & - n_{z}^{2,2}  & 0       & 0  &  n_{z}^{2,2} & 0            \\
    % 0 & 0 & 0 & 0 & - n_{z}^{2,2}  &  n_{z}^{2,2} & 0 &  0  &  0         \\
    % 0 & 0 & 0 & 0 & 0 & - n_{z}^{2,3}  &  0      & 0     &  n_{z}^{2,3}         \\
    % 0 & 0 & 0 & 0 & 0 & 0  &  0      & 0     &  0         \\
    % % 0 & 0 & 0 & 0 & 0 & - n_{z}^{2,3}  &  n_{z}^{2,3} & 0 &  0        \\
    - n_{z}^{1,1}  &  0                      & 0  & n_{z}^{1,1}    & 0 & 0 \\[3pt]
    - n_{z}^{1,1}  &  n_{z}^{1,1}  &  0  & 0 & 0  &  0               \\[3pt]
    0 & - n_{z}^{1,2}  &  0                   & 0 &  n_{z}^{1,2}   & 0     \\[3pt]
    0 & - n_{z}^{1,2}  &  n_{z}^{1,2}   & 0 &  0  &  0      \\[3pt]
    0 & 0 & - n_{z}^{1,3}  &  0             & 0   &  n_{z}^{1,3}  \\[3pt]
    0 & 0 & - n_{z}^{1,3}  &  0 & 0 &  0       \\[3pt]
    % 0 & 0 &  0  &  0 & 0 &  0         \\[3pt]
    0 & 0 & 0 & - n_{z}^{2,1}  &  0         & 0          \\[3pt]
    0 & 0 & 0 & - n_{z}^{2,1}  &  n_{z}^{2,1} & 0       \\[3pt]
    0 & 0 & 0 & 0 & - n_{z}^{2,2}  & 0                  \\[3pt]
    0 & 0 & 0 & 0 & - n_{z}^{2,2}  &  n_{z}^{2,2}         \\[3pt]
    0 & 0 & 0 & 0 & 0 & - n_{z}^{2,3}          \\[3pt]
    0 & 0 & 0 & 0 & 0 & - n_{z}^{2,3}         \\[3pt]
    % 0 & 0 & 0 & 0 & 0 & - n_{z}^{2,3}  &  n_{z}^{2,3} & 0 &  0        \\[3pt]
\end{pmatrix}}_{\text{\Large{M}}}
\underbrace{\begin{pmatrix}
    z_{1, 1} \\[3pt]
    z_{1, 2} \\[3pt]
    z_{1, 3} \\[3pt]
    z_{2, 1} \\[3pt]
    z_{2, 2} \\[3pt]
    z_{2, 3}
\end{pmatrix}}_{\text{\Large{z}}}
=
\underbrace{\begin{pmatrix}
    n_{y}^{1, 1} \\[3pt]
    n_{x}^{1, 1} \\[3pt]
    n_{y}^{1, 2} \\[3pt]
    n_{x}^{1, 2} \\[3pt]
    n_{y}^{1, 3} \\[3pt]
    n_{x}^{1, 3} \\[3pt]
    n_{x}^{2, 1} \\[3pt]
    n_{y}^{2, 1} \\[3pt]
    n_{x}^{2, 2} \\[3pt]
    n_{y}^{2, 2} \\[3pt]
    n_{x}^{2, 3} \\[3pt]
    n_{y}^{2, 3}
\end{pmatrix}}_{\text{\Large{v}}}
\]

\newpage
A modo de ejemplo, tomemos la tercer fila y hagamos el producto:

\begin{center}
    $-n_{z}^{1, 2} * z_{1,2} + n_{z}^{1, 2} * z_{1, 3} \iff n_{z}^{1, 2} * z_{1, 3} -n_{z}^{1, 2} * z_{1,2}$
\end{center}

y vemos que se corresponde con nuestro sistema original. Puede verse además que las dimensiones para realizar el producto cuadran perfectamente. Si $n'$ y $m'$ eran el alto y ancho de la imagen original, la nueva matriz tiene $2*n'*m'$ filas y $n'*m'$ columnas.

Si bien la matriz esta planteada con unas dimensiones en particular, por su forma es sencillo de generalizar. Dado un cierto píxel $(x, y)$, las dos ecuaciones correspondientes son:

\[
\begin{pmatrix}
    0 & \dots & 0 & n_{z} & 0     & \dots &       & n_{z} & \dots  \\
    0 & \dots & 0 & n_{z} & n_{z} & 0     & \dots & \dots & \dots
\end{pmatrix}
\]

Para cada píxel tenemos la primer ecuacion correspondiente a $n_y$, donde los dos $n_z$ están separados a $m'$ de distancia (\textit{ancho de la imagen original}), y en la segunda ecuación se encuentra la correspondiente a $n_x$ donde los dos $n_z$ se encuentran juntos. También puede verse que cada vez que pasamos al siguiente píxel bajando de fila se produce un corrimiento en una columna hacia la derecha. Hay que tener especial cuidado con los bordes de la imagen, porque el producto dará como resultado una ecuación erronea. Para que esto no sea un problema, colocamos ceros en los lugares problemáticos. \\

Queremos entonces resolver el sistema:

\begin{center}
$M z = v$
\end{center}

Multiplicando por $M^{t}$ a ambos lados se obtiene:
\begin{center}
\[\underbrace{M^{t} M}_{\text{A}} z = \underbrace{M^{t} v}_{\text{b}}\]
\end{center}

Para así llegar al sistema final que nos interesa resolver
\begin{center}
$A z = b$
\end{center}

La matriz $A$ no es cualquier cosa, sino que tiene una forma particular. En primer lugar, es simétrica porque es el resultado de haber multiplicado una matriz con su traspuesta.

En este caso si $(a, b)$ es nuestro píxel escribiremos  $n_{a,b}$ en vez de $n^{a,b}$ para no confundir con el exponente que está potenciando al elemento. Veamos como es la forma de $A$, obtenida simplemente haciendo la cuenta $M^t M$

\todo[inline]{Hacer bien la cuenta y completar. Ojo con los signos porque la matriz M ahora tiene signos menos.}
\todo[inline]{Luego de hacer la cuenta modificar en el maincpp porque puede que tenga errores el 'matrizProfundidadesPosta'. Especial atencion a los saltos donde hay ceros}

\[
\begin{pmatrix}
    2 n_{1,1}^{2}&  n_{1,1}^{2}   &  0        & n_{1,1}^{2}   & 0         & 0            \\[10pt]

    n_{1,1}^{2}&  n_{1,1}^{2} +  2 n_{1,2}^{2}   &  n_{1,2}^{2}        & 0     & n_{1,2}^{2}         & 0            \\[10pt]

    0          &  n_{1,2}^{2}  &  n_{1,2}^{2} + 2n_{1,3}^{2} & n_{1,3}^{2}   & 0  & n_{1,3}^{2}            \\[10pt]

    n_{1,1}^{2}&  0            &  n_{1,3}^{2} & COMPLETARRRRR & 0         & 0            \\[10pt]

    0          &   n_{1,2}^{2} & 0           & 0         & COMPLETARRRRR           & 0  \\[10pt]

    0          &              0&  n_{1,3}^{2} & 0         & 0         &   n_{1,3}^{2}           \\[10pt]

\end{pmatrix}
\]

\todo[inline]{Contar un poco de como construir el caso general}

Si bien este fue un pequeño ejemplo, la matriz en caso general contiene \textbf{muchos} ceros. Originalmente nuestras matrices estaban hechas utilizando simples vectores. Esto es un problema \textbf{enorme} para la implementación, porque si tomamos una imagen mas grande, por ejemplo de $250*270$ px (como el tamaño de las normales provistas por la cátedra) la cantidad de elementos en la matriz será de
\begin{center}
    $(250*270)^2 = 4 556 250 000$
\end{center}

Y dado que un \textit{double} ocupa 8 bytes, el tamaño total de la matriz sería
\begin{center}
    $4 556 250 000 * 8 bytes = 36.45 gigabytes$
\end{center}

Como no pudimos conseguir esa cantidad de memoria ni juntando a todos los miembros del equipo, decidimos hacer algo mejor.




\subsection{Cholesky}
\todo[inline]{algo}

\section{Resultados}
\todo[inline] {Dar imagenes minimo del resultado final}


\section{Experimentación}

\todo[inline]{PENSAR MAS}

\todo[inline]{Mostrar como con diferentes luces obtenemos diferentes normales}

\todo[inline]{Diferencias de tiempos EG vs LU, con si y mascara mascara}

\todo[inline]{Mostrar resultados finales con mismas luces pero propias vs catedra}

